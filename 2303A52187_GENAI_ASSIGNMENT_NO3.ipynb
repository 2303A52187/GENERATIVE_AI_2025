{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52187/GENERATIVE_AI_2025/blob/main/2303A52187_GENAI_ASSIGNMENT_NO3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    return 5 * x*4 + 3 * x*2 + 10\n",
        "def df(x):\n",
        "    return 20 * x**3 + 6 * x\n",
        "def gradient_descent_f(learning_rate=0.001, iterations=1000):\n",
        "    x = 1\n",
        "    for i in range(iterations):\n",
        "        grad = df(x)\n",
        "        x = x - learning_rate * grad\n",
        "    return x\n",
        "x_min_f = gradient_descent_f()\n",
        "print(f\"The value of x that minimizes f(x) is: {x_min_f}\")"
      ],
      "metadata": {
        "id": "9t6ojN-wysVz",
        "outputId": "969f5da8-329a-44ce-9dd6-2c81d3d567d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x that minimizes f(x) is: 0.001161634189870079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def g(x, y):\n",
        "    return 3 * x**2 + 5 * math.exp(-y) + 10\n",
        "def dg_dx(x, y):\n",
        "    return 6 * x\n",
        "def dg_dy(x, y):\n",
        "    return -5 * math.exp(-y)\n",
        "def gradient_descent_g(learning_rate=0.01, iterations=1000):\n",
        "    x, y = 10, 10\n",
        "    for i in range(iterations):\n",
        "        grad_x = dg_dx(x, y)\n",
        "        grad_y = dg_dy(x, y)\n",
        "        x = x - learning_rate * grad_x\n",
        "        y = y - learning_rate * grad_y\n",
        "    return x, y\n",
        "x_min_g, y_min_g = gradient_descent_g()\n",
        "print(f\"The values of x and y that minimize g(x, y) are: x = {x_min_g}, y = {y_min_g}\")"
      ],
      "metadata": {
        "id": "hegswk8Zy6pn",
        "outputId": "372d2dbf-bd51-47dd-9ab8-3969fcc2a9b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The values of x and y that minimize g(x, y) are: x = 1.3423123924933693e-26, y = 10.002267426506178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def z(x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "def dz_dx(x):\n",
        "    sigmoid = 1 / (1 + math.exp(-x))\n",
        "    return sigmoid * (1 - sigmoid)\n",
        "\n",
        "def gradient_descent_z(learning_rate=0.01, iterations=1000):\n",
        "    x = 10\n",
        "    for i in range(iterations):\n",
        "        grad = dz_dx(x)\n",
        "        x = x - learning_rate * grad\n",
        "    return x\n",
        "x_min_z = gradient_descent_z()\n",
        "print(f\"The value of x that minimizes z(x) is: {x_min_z}\")"
      ],
      "metadata": {
        "id": "h4cfTTRYzAs4",
        "outputId": "56aec09e-83da-4e64-ff3a-f8021afcb077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x that minimizes z(x) is: 9.9995459389649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X= [1, 2, 3, 4, 5]\n",
        "Y = [2, 4, 6, 8, 10]\n",
        "def predicted_output(x, M, C):\n",
        "    return M * x + C\n",
        "def square_error(M, C):\n",
        "    total_error = 0\n",
        "    for x, y in zip(X, Y):\n",
        "        y_pred = predicted_output(x, M, C)\n",
        "        total_error += (y - y_pred)**2\n",
        "    return total_error\n",
        "def grad_se_M(M, C):\n",
        "    grad = 0\n",
        "    for x, y in zip(X, Y):\n",
        "        grad += -2 * x * (y - (M * x + C))\n",
        "    return grad\n",
        "def grad_se_C(M, C):\n",
        "    grad = 0\n",
        "    for x, y in zip(X, Y):\n",
        "        grad += -2 * (y - (M * x + C))\n",
        "    return grad\n",
        "def gradient_descent_se(learning_rate=0.01, iterations=1000):\n",
        "    M, C = 0, 0\n",
        "    for i in range(iterations):\n",
        "        grad_M = grad_se_M(M, C)\n",
        "        grad_C = grad_se_C(M, C)\n",
        "        M = M - learning_rate * grad_M\n",
        "        C = C - learning_rate * grad_C\n",
        "    return M, C\n",
        "M_optimal, C_optimal = gradient_descent_se()\n",
        "print(f\"The optimal values of M and C that minimize the square error are: M = {M_optimal}, C = {C_optimal}\")"
      ],
      "metadata": {
        "id": "BaxWQIrNzJ9E",
        "outputId": "e4527d49-e5b3-40a6-ca99-2c326445f2dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The optimal values of M and C that minimize the square error are: M = 1.9999999943842544, C = 2.0274623625998433e-08\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}