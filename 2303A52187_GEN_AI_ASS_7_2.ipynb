{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52187/GENERATIVE_AI_2025/blob/main/2303A52187_GEN_AI_ASS_7_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load Dataset\n",
        "dataset_url = \"https://drive.google.com/uc?id=1AcdENlVm5dccNyo_vgdMbneX8YVvH5R3\"\n",
        "df = pd.read_csv(dataset_url)\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Convert categorical columns to numeric using LabelEncoder\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Save encoders for deployment\n",
        "\n",
        "# Separate features and target\n",
        "y = df.iloc[:, -1].values  # Last column as target\n",
        "X = df.iloc[:, :-1].values  # All other columns as features\n",
        "\n",
        "# Normalize Features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset into Training and Testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build ANN Model with specified architecture\n",
        "model = Sequential([\n",
        "    Dense(10, activation='tanh', input_shape=(X_train.shape[1],)),  # Hidden Layer 1\n",
        "    Dense(15, activation='tanh'),  # Hidden Layer 2\n",
        "    Dense(20, activation='tanh'),  # Hidden Layer 3\n",
        "    Dense(10, activation='tanh'),  # Hidden Layer 4\n",
        "    Dense(5, activation='tanh'),   # Hidden Layer 5\n",
        "    Dense(1, activation='sigmoid')  # Output Layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "model.fit(X_train, y_train, epochs=250, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Save Model\n",
        "model.save(\"diabetes_ann_model.h5\")\n",
        "\n",
        "# Predict on Training and Test Data\n",
        "y_pred_train = (model.predict(X_train) > 0.5).astype(int)\n",
        "y_pred_test = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Calculate Performance Metrics\n",
        "train_acc = accuracy_score(y_train, y_pred_train)\n",
        "test_acc = accuracy_score(y_test, y_pred_test)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "report = classification_report(y_test, y_pred_test)\n",
        "\n",
        "# Display Results\n",
        "print(f\"\\nTraining Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_acc:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Load the Model for Deployment\n",
        "loaded_model = keras.models.load_model(\"diabetes_ann_model.h5\")\n",
        "\n",
        "# Function to Predict Diabetes\n",
        "def predict_diabetes(input_data):\n",
        "    \"\"\"\n",
        "    This function takes a raw input data row, processes it, and predicts diabetes.\n",
        "    \"\"\"\n",
        "    input_data = np.array(input_data).reshape(1, -1)  # Ensure correct shape\n",
        "    input_scaled = scaler.transform(input_data)  # Apply Standard Scaling\n",
        "    prediction = loaded_model.predict(input_scaled)[0, 0]\n",
        "    return \"Diabetic\" if prediction > 0.5 else \"Non-Diabetic\"\n",
        "\n",
        "# Example Prediction\n",
        "sample_patient = X_test[0]  # Get a sample from test data\n",
        "prediction_result = predict_diabetes(sample_patient)\n",
        "print(f\"\\nPredicted Diagnosis: {prediction_result}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4jYXElgY6KF2",
        "outputId": "d96345ee-f114-4deb-b098-51f9b12e1295",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.4014 - loss: 0.5963 - val_accuracy: 0.3578 - val_loss: 0.4905\n",
            "Epoch 2/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3725 - loss: 0.4904 - val_accuracy: 0.3670 - val_loss: 0.3808\n",
            "Epoch 3/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3813 - loss: 0.3776 - val_accuracy: 0.3945 - val_loss: 0.2676\n",
            "Epoch 4/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4554 - loss: 0.2705 - val_accuracy: 0.4037 - val_loss: 0.1587\n",
            "Epoch 5/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4590 - loss: 0.1531 - val_accuracy: 0.4037 - val_loss: 0.0537\n",
            "Epoch 6/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.4587 - loss: 0.0390 - val_accuracy: 0.4128 - val_loss: -0.0465\n",
            "Epoch 7/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.4529 - loss: -0.0695 - val_accuracy: 0.3578 - val_loss: -0.1448\n",
            "Epoch 8/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.4513 - loss: -0.0529 - val_accuracy: 0.3670 - val_loss: -0.2184\n",
            "Epoch 9/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.3988 - loss: 0.0237 - val_accuracy: 0.3670 - val_loss: -0.2780\n",
            "Epoch 10/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4579 - loss: -0.1423 - val_accuracy: 0.3670 - val_loss: -0.3116\n",
            "Epoch 11/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4741 - loss: -0.0627 - val_accuracy: 0.3670 - val_loss: -0.3479\n",
            "Epoch 12/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4470 - loss: -0.2550 - val_accuracy: 0.3670 - val_loss: -0.3728\n",
            "Epoch 13/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4498 - loss: -0.2166 - val_accuracy: 0.3670 - val_loss: -0.3957\n",
            "Epoch 14/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4281 - loss: -0.1856 - val_accuracy: 0.3670 - val_loss: -0.4073\n",
            "Epoch 15/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4688 - loss: -0.1936 - val_accuracy: 0.3670 - val_loss: -0.4179\n",
            "Epoch 16/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4311 - loss: -0.2650 - val_accuracy: 0.3670 - val_loss: -0.4222\n",
            "Epoch 17/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4386 - loss: -0.3006 - val_accuracy: 0.3670 - val_loss: -0.4444\n",
            "Epoch 18/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4365 - loss: -0.3942 - val_accuracy: 0.3670 - val_loss: -0.4568\n",
            "Epoch 19/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4522 - loss: -0.2096 - val_accuracy: 0.3670 - val_loss: -0.4729\n",
            "Epoch 20/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4450 - loss: -0.4743 - val_accuracy: 0.3670 - val_loss: -0.4854\n",
            "Epoch 21/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4530 - loss: -0.3488 - val_accuracy: 0.3670 - val_loss: -0.4879\n",
            "Epoch 22/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4417 - loss: -0.3860 - val_accuracy: 0.3761 - val_loss: -0.4850\n",
            "Epoch 23/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4616 - loss: -0.5442 - val_accuracy: 0.3670 - val_loss: -0.5119\n",
            "Epoch 24/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4444 - loss: -0.3346 - val_accuracy: 0.3670 - val_loss: -0.5179\n",
            "Epoch 25/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4649 - loss: -0.6198 - val_accuracy: 0.3670 - val_loss: -0.5218\n",
            "Epoch 26/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4554 - loss: -0.4042 - val_accuracy: 0.3670 - val_loss: -0.5276\n",
            "Epoch 27/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4497 - loss: -0.5296 - val_accuracy: 0.3670 - val_loss: -0.5310\n",
            "Epoch 28/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4430 - loss: -0.4432 - val_accuracy: 0.3670 - val_loss: -0.5450\n",
            "Epoch 29/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4759 - loss: -0.3939 - val_accuracy: 0.3670 - val_loss: -0.5495\n",
            "Epoch 30/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4681 - loss: -0.3979 - val_accuracy: 0.3578 - val_loss: -0.5791\n",
            "Epoch 31/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4472 - loss: -0.3334 - val_accuracy: 0.3670 - val_loss: -0.5730\n",
            "Epoch 32/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4404 - loss: -0.7743 - val_accuracy: 0.3670 - val_loss: -0.5864\n",
            "Epoch 33/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4076 - loss: -0.6356 - val_accuracy: 0.3670 - val_loss: -0.6077\n",
            "Epoch 34/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4584 - loss: -0.5026 - val_accuracy: 0.3761 - val_loss: -0.6040\n",
            "Epoch 35/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4408 - loss: -0.3589 - val_accuracy: 0.3761 - val_loss: -0.6144\n",
            "Epoch 36/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4696 - loss: -0.4951 - val_accuracy: 0.3761 - val_loss: -0.6088\n",
            "Epoch 37/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4656 - loss: -0.3339 - val_accuracy: 0.3670 - val_loss: -0.6280\n",
            "Epoch 38/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4614 - loss: -0.5328 - val_accuracy: 0.3761 - val_loss: -0.6637\n",
            "Epoch 39/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4631 - loss: -0.6597 - val_accuracy: 0.3761 - val_loss: -0.6609\n",
            "Epoch 40/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4505 - loss: -0.6264 - val_accuracy: 0.3853 - val_loss: -0.6540\n",
            "Epoch 41/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4785 - loss: -0.6124 - val_accuracy: 0.3761 - val_loss: -0.6862\n",
            "Epoch 42/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4644 - loss: -0.5252 - val_accuracy: 0.3761 - val_loss: -0.6973\n",
            "Epoch 43/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4840 - loss: -0.7061 - val_accuracy: 0.3761 - val_loss: -0.7115\n",
            "Epoch 44/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4569 - loss: -0.5241 - val_accuracy: 0.3761 - val_loss: -0.7350\n",
            "Epoch 45/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4555 - loss: -0.8566 - val_accuracy: 0.3761 - val_loss: -0.7088\n",
            "Epoch 46/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4795 - loss: -0.6778 - val_accuracy: 0.3761 - val_loss: -0.7545\n",
            "Epoch 47/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4584 - loss: -0.8385 - val_accuracy: 0.3945 - val_loss: -0.7333\n",
            "Epoch 48/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4606 - loss: -0.7063 - val_accuracy: 0.3761 - val_loss: -0.7757\n",
            "Epoch 49/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4797 - loss: -0.9630 - val_accuracy: 0.3670 - val_loss: -0.7494\n",
            "Epoch 50/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4613 - loss: -0.8650 - val_accuracy: 0.3670 - val_loss: -0.7779\n",
            "Epoch 51/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4609 - loss: -0.6083 - val_accuracy: 0.3578 - val_loss: -0.8218\n",
            "Epoch 52/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4586 - loss: -0.7665 - val_accuracy: 0.3670 - val_loss: -0.8221\n",
            "Epoch 53/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4851 - loss: -0.9754 - val_accuracy: 0.3578 - val_loss: -0.8107\n",
            "Epoch 54/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4776 - loss: -0.7196 - val_accuracy: 0.3578 - val_loss: -0.8505\n",
            "Epoch 55/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4694 - loss: -1.0862 - val_accuracy: 0.3486 - val_loss: -0.8686\n",
            "Epoch 56/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4830 - loss: -1.1402 - val_accuracy: 0.3578 - val_loss: -0.8632\n",
            "Epoch 57/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4379 - loss: -0.9114 - val_accuracy: 0.3578 - val_loss: -0.9186\n",
            "Epoch 58/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4878 - loss: -1.0709 - val_accuracy: 0.3670 - val_loss: -0.8938\n",
            "Epoch 59/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4623 - loss: -0.9034 - val_accuracy: 0.3578 - val_loss: -0.9184\n",
            "Epoch 60/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4502 - loss: -0.6968 - val_accuracy: 0.3394 - val_loss: -0.9296\n",
            "Epoch 61/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5186 - loss: -0.9553 - val_accuracy: 0.3578 - val_loss: -0.9382\n",
            "Epoch 62/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4942 - loss: -0.7945 - val_accuracy: 0.3578 - val_loss: -0.9619\n",
            "Epoch 63/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4818 - loss: -0.8956 - val_accuracy: 0.3486 - val_loss: -0.9505\n",
            "Epoch 64/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4943 - loss: -0.9689 - val_accuracy: 0.3578 - val_loss: -0.9934\n",
            "Epoch 65/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4931 - loss: -0.9708 - val_accuracy: 0.3486 - val_loss: -0.9529\n",
            "Epoch 66/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4697 - loss: -1.3628 - val_accuracy: 0.3578 - val_loss: -1.0319\n",
            "Epoch 67/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5054 - loss: -1.0767 - val_accuracy: 0.3486 - val_loss: -0.9721\n",
            "Epoch 68/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4845 - loss: -1.0691 - val_accuracy: 0.3486 - val_loss: -1.0172\n",
            "Epoch 69/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4629 - loss: -1.1203 - val_accuracy: 0.3578 - val_loss: -1.0505\n",
            "Epoch 70/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4899 - loss: -0.8088 - val_accuracy: 0.3394 - val_loss: -1.0315\n",
            "Epoch 71/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5004 - loss: -1.0575 - val_accuracy: 0.3486 - val_loss: -1.0463\n",
            "Epoch 72/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4793 - loss: -1.0657 - val_accuracy: 0.3578 - val_loss: -1.0686\n",
            "Epoch 73/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4745 - loss: -1.1792 - val_accuracy: 0.3578 - val_loss: -1.0540\n",
            "Epoch 74/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4661 - loss: -1.1461 - val_accuracy: 0.3578 - val_loss: -1.0941\n",
            "Epoch 75/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5103 - loss: -1.3049 - val_accuracy: 0.3486 - val_loss: -1.0761\n",
            "Epoch 76/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4959 - loss: -1.2539 - val_accuracy: 0.3486 - val_loss: -1.0990\n",
            "Epoch 77/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4533 - loss: -1.6420 - val_accuracy: 0.3394 - val_loss: -1.1062\n",
            "Epoch 78/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4851 - loss: -1.4686 - val_accuracy: 0.3394 - val_loss: -1.1181\n",
            "Epoch 79/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4716 - loss: -1.3266 - val_accuracy: 0.3761 - val_loss: -1.1542\n",
            "Epoch 80/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5133 - loss: -1.2710 - val_accuracy: 0.3486 - val_loss: -1.1417\n",
            "Epoch 81/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5095 - loss: -1.0732 - val_accuracy: 0.3578 - val_loss: -1.1478\n",
            "Epoch 82/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4996 - loss: -1.2882 - val_accuracy: 0.3761 - val_loss: -1.1826\n",
            "Epoch 83/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5254 - loss: -1.0864 - val_accuracy: 0.3486 - val_loss: -1.1427\n",
            "Epoch 84/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5033 - loss: -1.6153 - val_accuracy: 0.3486 - val_loss: -1.1715\n",
            "Epoch 85/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5154 - loss: -1.2969 - val_accuracy: 0.3303 - val_loss: -1.1721\n",
            "Epoch 86/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4966 - loss: -1.0122 - val_accuracy: 0.3486 - val_loss: -1.1910\n",
            "Epoch 87/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4805 - loss: -1.3824 - val_accuracy: 0.3578 - val_loss: -1.1903\n",
            "Epoch 88/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4642 - loss: -1.8166 - val_accuracy: 0.3486 - val_loss: -1.1858\n",
            "Epoch 89/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4913 - loss: -1.7003 - val_accuracy: 0.3486 - val_loss: -1.2139\n",
            "Epoch 90/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5141 - loss: -1.7892 - val_accuracy: 0.3486 - val_loss: -1.2041\n",
            "Epoch 91/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4344 - loss: -1.7743 - val_accuracy: 0.3578 - val_loss: -1.2301\n",
            "Epoch 92/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5014 - loss: -1.6281 - val_accuracy: 0.3578 - val_loss: -1.2248\n",
            "Epoch 93/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4836 - loss: -1.4353 - val_accuracy: 0.3578 - val_loss: -1.2125\n",
            "Epoch 94/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4965 - loss: -1.5748 - val_accuracy: 0.3394 - val_loss: -1.2450\n",
            "Epoch 95/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4971 - loss: -1.4901 - val_accuracy: 0.3394 - val_loss: -1.2127\n",
            "Epoch 96/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4962 - loss: -1.4097 - val_accuracy: 0.3578 - val_loss: -1.2555\n",
            "Epoch 97/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4769 - loss: -1.6952 - val_accuracy: 0.3486 - val_loss: -1.2580\n",
            "Epoch 98/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5013 - loss: -1.3881 - val_accuracy: 0.3578 - val_loss: -1.2803\n",
            "Epoch 99/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4819 - loss: -1.7295 - val_accuracy: 0.3486 - val_loss: -1.2731\n",
            "Epoch 100/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5395 - loss: -1.4487 - val_accuracy: 0.3578 - val_loss: -1.2654\n",
            "Epoch 101/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4951 - loss: -1.7853 - val_accuracy: 0.3486 - val_loss: -1.2583\n",
            "Epoch 102/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5028 - loss: -1.6632 - val_accuracy: 0.3394 - val_loss: -1.2714\n",
            "Epoch 103/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5125 - loss: -1.7764 - val_accuracy: 0.3394 - val_loss: -1.2771\n",
            "Epoch 104/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5035 - loss: -1.9891 - val_accuracy: 0.3486 - val_loss: -1.2748\n",
            "Epoch 105/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4801 - loss: -1.9937 - val_accuracy: 0.3394 - val_loss: -1.2820\n",
            "Epoch 106/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5169 - loss: -1.6312 - val_accuracy: 0.3394 - val_loss: -1.2692\n",
            "Epoch 107/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4765 - loss: -2.2525 - val_accuracy: 0.3486 - val_loss: -1.2708\n",
            "Epoch 108/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5046 - loss: -1.9802 - val_accuracy: 0.3394 - val_loss: -1.2785\n",
            "Epoch 109/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5067 - loss: -1.9440 - val_accuracy: 0.3486 - val_loss: -1.3068\n",
            "Epoch 110/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5100 - loss: -1.8833 - val_accuracy: 0.3394 - val_loss: -1.2670\n",
            "Epoch 111/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4483 - loss: -1.9657 - val_accuracy: 0.3303 - val_loss: -1.2890\n",
            "Epoch 112/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4967 - loss: -2.1320 - val_accuracy: 0.3394 - val_loss: -1.2754\n",
            "Epoch 113/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5170 - loss: -2.0196 - val_accuracy: 0.3486 - val_loss: -1.3003\n",
            "Epoch 114/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4780 - loss: -2.4436 - val_accuracy: 0.3486 - val_loss: -1.2573\n",
            "Epoch 115/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4887 - loss: -2.1514 - val_accuracy: 0.3303 - val_loss: -1.3045\n",
            "Epoch 116/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5166 - loss: -1.8080 - val_accuracy: 0.3394 - val_loss: -1.2983\n",
            "Epoch 117/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5002 - loss: -1.8632 - val_accuracy: 0.3303 - val_loss: -1.3055\n",
            "Epoch 118/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5146 - loss: -1.7751 - val_accuracy: 0.3394 - val_loss: -1.3104\n",
            "Epoch 119/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5050 - loss: -2.0627 - val_accuracy: 0.3303 - val_loss: -1.3198\n",
            "Epoch 120/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5117 - loss: -2.2354 - val_accuracy: 0.3303 - val_loss: -1.2990\n",
            "Epoch 121/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4775 - loss: -2.0025 - val_accuracy: 0.3394 - val_loss: -1.3131\n",
            "Epoch 122/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5423 - loss: -1.7616 - val_accuracy: 0.3394 - val_loss: -1.2728\n",
            "Epoch 123/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5495 - loss: -1.7429 - val_accuracy: 0.3303 - val_loss: -1.3294\n",
            "Epoch 124/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5302 - loss: -1.8531 - val_accuracy: 0.3303 - val_loss: -1.2922\n",
            "Epoch 125/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5186 - loss: -1.9146 - val_accuracy: 0.3303 - val_loss: -1.3363\n",
            "Epoch 126/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5239 - loss: -2.2689 - val_accuracy: 0.3394 - val_loss: -1.2790\n",
            "Epoch 127/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4948 - loss: -2.1142 - val_accuracy: 0.3394 - val_loss: -1.3437\n",
            "Epoch 128/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5266 - loss: -1.8152 - val_accuracy: 0.3394 - val_loss: -1.3020\n",
            "Epoch 129/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5140 - loss: -1.9821 - val_accuracy: 0.3486 - val_loss: -1.3069\n",
            "Epoch 130/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5322 - loss: -2.4007 - val_accuracy: 0.3486 - val_loss: -1.3045\n",
            "Epoch 131/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5375 - loss: -1.4855 - val_accuracy: 0.3303 - val_loss: -1.3532\n",
            "Epoch 132/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4974 - loss: -2.1038 - val_accuracy: 0.3394 - val_loss: -1.3294\n",
            "Epoch 133/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5332 - loss: -1.9629 - val_accuracy: 0.3394 - val_loss: -1.3115\n",
            "Epoch 134/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5450 - loss: -2.1267 - val_accuracy: 0.3303 - val_loss: -1.3222\n",
            "Epoch 135/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5365 - loss: -1.9744 - val_accuracy: 0.3303 - val_loss: -1.3090\n",
            "Epoch 136/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5560 - loss: -2.2971 - val_accuracy: 0.3303 - val_loss: -1.3178\n",
            "Epoch 137/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5183 - loss: -2.5847 - val_accuracy: 0.3394 - val_loss: -1.2879\n",
            "Epoch 138/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5118 - loss: -2.5110 - val_accuracy: 0.3394 - val_loss: -1.3386\n",
            "Epoch 139/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5409 - loss: -2.2494 - val_accuracy: 0.3394 - val_loss: -1.3113\n",
            "Epoch 140/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5123 - loss: -3.3085 - val_accuracy: 0.3394 - val_loss: -1.2934\n",
            "Epoch 141/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5494 - loss: -2.3400 - val_accuracy: 0.3394 - val_loss: -1.3357\n",
            "Epoch 142/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5598 - loss: -2.2345 - val_accuracy: 0.3394 - val_loss: -1.3129\n",
            "Epoch 143/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5164 - loss: -2.3416 - val_accuracy: 0.3394 - val_loss: -1.3203\n",
            "Epoch 144/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5152 - loss: -2.4872 - val_accuracy: 0.3394 - val_loss: -1.3419\n",
            "Epoch 145/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5291 - loss: -2.3807 - val_accuracy: 0.3303 - val_loss: -1.2988\n",
            "Epoch 146/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5152 - loss: -2.4476 - val_accuracy: 0.3394 - val_loss: -1.3755\n",
            "Epoch 147/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5174 - loss: -2.2626 - val_accuracy: 0.3394 - val_loss: -1.3146\n",
            "Epoch 148/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5351 - loss: -2.3902 - val_accuracy: 0.3486 - val_loss: -1.3773\n",
            "Epoch 149/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5369 - loss: -2.2500 - val_accuracy: 0.3303 - val_loss: -1.3833\n",
            "Epoch 150/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5065 - loss: -2.7378 - val_accuracy: 0.3303 - val_loss: -1.3306\n",
            "Epoch 151/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5076 - loss: -3.0422 - val_accuracy: 0.3394 - val_loss: -1.4040\n",
            "Epoch 152/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5343 - loss: -3.0461 - val_accuracy: 0.3394 - val_loss: -1.4296\n",
            "Epoch 153/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5148 - loss: -3.0499 - val_accuracy: 0.3394 - val_loss: -1.4029\n",
            "Epoch 154/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5253 - loss: -2.8133 - val_accuracy: 0.3486 - val_loss: -1.4418\n",
            "Epoch 155/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5261 - loss: -3.1336 - val_accuracy: 0.3486 - val_loss: -1.4551\n",
            "Epoch 156/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4951 - loss: -3.2351 - val_accuracy: 0.3303 - val_loss: -1.4032\n",
            "Epoch 157/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5300 - loss: -2.4601 - val_accuracy: 0.3394 - val_loss: -1.4548\n",
            "Epoch 158/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5267 - loss: -3.0588 - val_accuracy: 0.3486 - val_loss: -1.4631\n",
            "Epoch 159/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5370 - loss: -3.3678 - val_accuracy: 0.3394 - val_loss: -1.4512\n",
            "Epoch 160/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5387 - loss: -3.0305 - val_accuracy: 0.3486 - val_loss: -1.4702\n",
            "Epoch 161/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5417 - loss: -2.5872 - val_accuracy: 0.3394 - val_loss: -1.4897\n",
            "Epoch 162/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5177 - loss: -2.8241 - val_accuracy: 0.3394 - val_loss: -1.4525\n",
            "Epoch 163/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5317 - loss: -2.6749 - val_accuracy: 0.3394 - val_loss: -1.5210\n",
            "Epoch 164/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5380 - loss: -3.1427 - val_accuracy: 0.3303 - val_loss: -1.4958\n",
            "Epoch 165/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4977 - loss: -3.5406 - val_accuracy: 0.3486 - val_loss: -1.4903\n",
            "Epoch 166/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5068 - loss: -3.3806 - val_accuracy: 0.3394 - val_loss: -1.4945\n",
            "Epoch 167/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5278 - loss: -3.3275 - val_accuracy: 0.3394 - val_loss: -1.5014\n",
            "Epoch 168/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5002 - loss: -3.5364 - val_accuracy: 0.3486 - val_loss: -1.5233\n",
            "Epoch 169/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5240 - loss: -3.3252 - val_accuracy: 0.3486 - val_loss: -1.5450\n",
            "Epoch 170/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5214 - loss: -3.7622 - val_accuracy: 0.3486 - val_loss: -1.5232\n",
            "Epoch 171/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5451 - loss: -3.1580 - val_accuracy: 0.3394 - val_loss: -1.5802\n",
            "Epoch 172/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5208 - loss: -3.3605 - val_accuracy: 0.3578 - val_loss: -1.5730\n",
            "Epoch 173/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5453 - loss: -2.7951 - val_accuracy: 0.3394 - val_loss: -1.5921\n",
            "Epoch 174/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5199 - loss: -3.6601 - val_accuracy: 0.3486 - val_loss: -1.6307\n",
            "Epoch 175/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5233 - loss: -3.1517 - val_accuracy: 0.3486 - val_loss: -1.6558\n",
            "Epoch 176/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5473 - loss: -3.3740 - val_accuracy: 0.3578 - val_loss: -1.7166\n",
            "Epoch 177/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5286 - loss: -3.4458 - val_accuracy: 0.3486 - val_loss: -1.7283\n",
            "Epoch 178/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5182 - loss: -2.7834 - val_accuracy: 0.3578 - val_loss: -1.7056\n",
            "Epoch 179/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5668 - loss: -3.4333 - val_accuracy: 0.3670 - val_loss: -1.7375\n",
            "Epoch 180/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5533 - loss: -3.3278 - val_accuracy: 0.3578 - val_loss: -1.6454\n",
            "Epoch 181/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5362 - loss: -3.2259 - val_accuracy: 0.3578 - val_loss: -1.6971\n",
            "Epoch 182/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5312 - loss: -3.6164 - val_accuracy: 0.3578 - val_loss: -1.6834\n",
            "Epoch 183/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5500 - loss: -3.1326 - val_accuracy: 0.3578 - val_loss: -1.7126\n",
            "Epoch 184/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5543 - loss: -2.9633 - val_accuracy: 0.3670 - val_loss: -1.7292\n",
            "Epoch 185/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5362 - loss: -3.4977 - val_accuracy: 0.3578 - val_loss: -1.6553\n",
            "Epoch 186/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5151 - loss: -2.9057 - val_accuracy: 0.3578 - val_loss: -1.6619\n",
            "Epoch 187/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5463 - loss: -3.3439 - val_accuracy: 0.3670 - val_loss: -1.7373\n",
            "Epoch 188/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5378 - loss: -4.2796 - val_accuracy: 0.3578 - val_loss: -1.6450\n",
            "Epoch 189/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5413 - loss: -3.0673 - val_accuracy: 0.3578 - val_loss: -1.6019\n",
            "Epoch 190/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5364 - loss: -3.6056 - val_accuracy: 0.3578 - val_loss: -1.6593\n",
            "Epoch 191/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5534 - loss: -3.5332 - val_accuracy: 0.3578 - val_loss: -1.5724\n",
            "Epoch 192/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5209 - loss: -3.5513 - val_accuracy: 0.3670 - val_loss: -1.6600\n",
            "Epoch 193/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5504 - loss: -3.2329 - val_accuracy: 0.3578 - val_loss: -1.5906\n",
            "Epoch 194/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5384 - loss: -4.1432 - val_accuracy: 0.3670 - val_loss: -1.6731\n",
            "Epoch 195/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5344 - loss: -4.1686 - val_accuracy: 0.3578 - val_loss: -1.6583\n",
            "Epoch 196/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5169 - loss: -3.8843 - val_accuracy: 0.3670 - val_loss: -1.6174\n",
            "Epoch 197/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5785 - loss: -3.0126 - val_accuracy: 0.3670 - val_loss: -1.5180\n",
            "Epoch 198/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5660 - loss: -4.2974 - val_accuracy: 0.3670 - val_loss: -1.6532\n",
            "Epoch 199/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5253 - loss: -3.9650 - val_accuracy: 0.3670 - val_loss: -1.5144\n",
            "Epoch 200/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5097 - loss: -3.9290 - val_accuracy: 0.3670 - val_loss: -1.6191\n",
            "Epoch 201/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5410 - loss: -4.0539 - val_accuracy: 0.3761 - val_loss: -1.6028\n",
            "Epoch 202/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5139 - loss: -4.1076 - val_accuracy: 0.3578 - val_loss: -1.6386\n",
            "Epoch 203/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5056 - loss: -4.6461 - val_accuracy: 0.3670 - val_loss: -1.5463\n",
            "Epoch 204/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5715 - loss: -4.0938 - val_accuracy: 0.3670 - val_loss: -1.5397\n",
            "Epoch 205/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4952 - loss: -4.3994 - val_accuracy: 0.3670 - val_loss: -1.4930\n",
            "Epoch 206/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5611 - loss: -3.8258 - val_accuracy: 0.3670 - val_loss: -1.6600\n",
            "Epoch 207/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5299 - loss: -3.7144 - val_accuracy: 0.3670 - val_loss: -1.4788\n",
            "Epoch 208/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5556 - loss: -4.1534 - val_accuracy: 0.3578 - val_loss: -1.6376\n",
            "Epoch 209/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5348 - loss: -4.4882 - val_accuracy: 0.3670 - val_loss: -1.4864\n",
            "Epoch 210/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5530 - loss: -4.0279 - val_accuracy: 0.3670 - val_loss: -1.5310\n",
            "Epoch 211/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5560 - loss: -3.9176 - val_accuracy: 0.3670 - val_loss: -1.5126\n",
            "Epoch 212/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5948 - loss: -3.3818 - val_accuracy: 0.3670 - val_loss: -1.5484\n",
            "Epoch 213/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5688 - loss: -3.7505 - val_accuracy: 0.3670 - val_loss: -1.4802\n",
            "Epoch 214/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5527 - loss: -4.4010 - val_accuracy: 0.3670 - val_loss: -1.5424\n",
            "Epoch 215/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5681 - loss: -3.6757 - val_accuracy: 0.3670 - val_loss: -1.5129\n",
            "Epoch 216/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5640 - loss: -4.2707 - val_accuracy: 0.3670 - val_loss: -1.4566\n",
            "Epoch 217/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5715 - loss: -5.0796 - val_accuracy: 0.3670 - val_loss: -1.5512\n",
            "Epoch 218/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5125 - loss: -5.1280 - val_accuracy: 0.3670 - val_loss: -1.3891\n",
            "Epoch 219/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5454 - loss: -4.0920 - val_accuracy: 0.3761 - val_loss: -1.3816\n",
            "Epoch 220/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5200 - loss: -4.8667 - val_accuracy: 0.3578 - val_loss: -1.3913\n",
            "Epoch 221/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5589 - loss: -4.0296 - val_accuracy: 0.3761 - val_loss: -1.2725\n",
            "Epoch 222/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5507 - loss: -4.2848 - val_accuracy: 0.3670 - val_loss: -1.3241\n",
            "Epoch 223/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5707 - loss: -4.9975 - val_accuracy: 0.3670 - val_loss: -1.2197\n",
            "Epoch 224/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5470 - loss: -4.4375 - val_accuracy: 0.3761 - val_loss: -1.4371\n",
            "Epoch 225/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5704 - loss: -4.7705 - val_accuracy: 0.3670 - val_loss: -1.1998\n",
            "Epoch 226/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5825 - loss: -4.6054 - val_accuracy: 0.3761 - val_loss: -1.4828\n",
            "Epoch 227/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5437 - loss: -5.0332 - val_accuracy: 0.3670 - val_loss: -1.3994\n",
            "Epoch 228/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5575 - loss: -4.8248 - val_accuracy: 0.3670 - val_loss: -1.3904\n",
            "Epoch 229/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5302 - loss: -4.9164 - val_accuracy: 0.3670 - val_loss: -1.3457\n",
            "Epoch 230/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5449 - loss: -4.7715 - val_accuracy: 0.3761 - val_loss: -1.3782\n",
            "Epoch 231/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5494 - loss: -5.0822 - val_accuracy: 0.3670 - val_loss: -1.3384\n",
            "Epoch 232/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5333 - loss: -5.1555 - val_accuracy: 0.3761 - val_loss: -1.5478\n",
            "Epoch 233/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5719 - loss: -4.2786 - val_accuracy: 0.3670 - val_loss: -1.4234\n",
            "Epoch 234/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5238 - loss: -5.6925 - val_accuracy: 0.3670 - val_loss: -1.4012\n",
            "Epoch 235/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5475 - loss: -4.8680 - val_accuracy: 0.3853 - val_loss: -1.4431\n",
            "Epoch 236/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5552 - loss: -5.4947 - val_accuracy: 0.3670 - val_loss: -1.4364\n",
            "Epoch 237/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5876 - loss: -3.9276 - val_accuracy: 0.3670 - val_loss: -1.3995\n",
            "Epoch 238/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5546 - loss: -4.9316 - val_accuracy: 0.3761 - val_loss: -1.5307\n",
            "Epoch 239/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5505 - loss: -5.0564 - val_accuracy: 0.3670 - val_loss: -1.3484\n",
            "Epoch 240/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5485 - loss: -4.7224 - val_accuracy: 0.3761 - val_loss: -1.4788\n",
            "Epoch 241/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5313 - loss: -4.8793 - val_accuracy: 0.3670 - val_loss: -1.4022\n",
            "Epoch 242/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5813 - loss: -4.4792 - val_accuracy: 0.3670 - val_loss: -1.4259\n",
            "Epoch 243/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5521 - loss: -4.4842 - val_accuracy: 0.3853 - val_loss: -1.5624\n",
            "Epoch 244/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5404 - loss: -5.6065 - val_accuracy: 0.3486 - val_loss: -1.2321\n",
            "Epoch 245/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5659 - loss: -4.9719 - val_accuracy: 0.3853 - val_loss: -1.6288\n",
            "Epoch 246/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5792 - loss: -5.3829 - val_accuracy: 0.3761 - val_loss: -1.7015\n",
            "Epoch 247/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5540 - loss: -4.6812 - val_accuracy: 0.3578 - val_loss: -1.4718\n",
            "Epoch 248/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5529 - loss: -5.1660 - val_accuracy: 0.3761 - val_loss: -1.6145\n",
            "Epoch 249/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5481 - loss: -5.5947 - val_accuracy: 0.3761 - val_loss: -1.5232\n",
            "Epoch 250/250\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5345 - loss: -4.5165 - val_accuracy: 0.3761 - val_loss: -1.5286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "\n",
            "Training Accuracy: 0.5642\n",
            "Testing Accuracy: 0.3761\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10 19  0]\n",
            " [ 8 31  0]\n",
            " [ 5 36  0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.34      0.38        29\n",
            "           1       0.36      0.79      0.50        39\n",
            "           2       0.00      0.00      0.00        41\n",
            "\n",
            "    accuracy                           0.38       109\n",
            "   macro avg       0.27      0.38      0.29       109\n",
            "weighted avg       0.24      0.38      0.28       109\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "\n",
            "Predicted Diagnosis: Diabetic\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}